{"componentChunkName":"component---src-templates-blog-post-js","path":"/blogs/circRNAs/","result":{"data":{"site":{"siteMetadata":{"title":"Twistronics Blog"}},"markdownRemark":{"id":"95caef39-d5b7-5113-8aaf-08fa7231f953","excerpt":"In this problem, we are given reference genome of Homo sapiens and\nthe genomic loci of all circRNAs. Given a certain genomic locus, our goal is to develop a…","html":"<p>In this problem, we are given reference genome of Homo sapiens and\nthe genomic loci of all circRNAs. Given a certain genomic locus, our goal is to develop a classifier\nto predict whether a pair of two loci will form a circRNA or not</p>\n<p>FASTA format is used to store reference genome. Details of this format can be found in (<a href=\"https://en.wikipedia.org/wiki/FASTA_format\">https://en.wikipedia.org/wiki/FASTA_format</a>). For python user, we use tools like biopython to parse fasta files (<a href=\"https://www.biostars.org/p/710/\">https://www.biostars.org/p/710/</a>).</p>\n<p>All other data are stored in BED format. chrom is the name of the chromosome. chromStart is\nthe starting position of the circRNA in the chromosome. Note that the first base in a chromosome\nis numbered 0; chromEnd is the ending position of the circRNA in the chromosome. Note that\nchromEnd base should not be included in the display of circRNA. For example, the first 200 bases\nof a chromosome are defined as chromStart=0, chromEnd=200, and span the bases numbered 0-199. strand defines the strand that circRNA lies in. Note that the FASTA file of the reference\ngenome only contains + strand, we should covert + strand to − strand. A complete description of BED format can be found in\n<a href=\"http://genome.ucsc.edu/FAQ/FAQformat.html#format1\">http://genome.ucsc.edu/FAQ/FAQformat.html#format1</a></p>\n<p>hsa hg19 Rybak2015.bed stores the genomic loci of circRNAs (positions where DNA sequence\ncan be transcribed and form circRNAs) of Homo sapiens. These data are considered as positive\nexamples.</p>\n<p>all exons.bed store thes genomic loci of exons. We should use this file to construct negative\nexamples. All exons that are not overlapped with circRNAs can be considered as negative examples.\nhg19 Alu.bed stores the genomic loci of Alu.</p>\n<h4>Dependency package:</h4>\n<ul>\n<li>Python 3.5</li>\n<li>Keras 1.2.0</li>\n<li>Tensorflow r0.12</li>\n<li>Numpy 1.7.1</li>\n</ul>\n<p>neural network structure:\n10000->640(relu)->dropout->64(relu)->dropout->1(sigmoid)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># coding:utf-8</span>\n\n\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> random\n<span class=\"token keyword\">from</span> matplotlib <span class=\"token keyword\">import</span> pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> sequence\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Dropout<span class=\"token punctuation\">,</span> Embedding<span class=\"token punctuation\">,</span> LSTM<span class=\"token punctuation\">,</span> Bidirectional<span class=\"token punctuation\">,</span> SimpleRNN\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>core <span class=\"token keyword\">import</span> Activation\n\ndna2int <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">'A'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'T'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'C'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'G'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'a'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'t'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'c'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">7</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'g'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'N'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">9</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dna2vec</span><span class=\"token punctuation\">(</span>dna<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    d <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> dna<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> c <span class=\"token operator\">==</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">continue</span>\n        temp_l <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        temp_l<span class=\"token punctuation\">[</span>dna2int<span class=\"token punctuation\">[</span>c<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n        d<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>temp_l<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> d\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dna_to_int</span><span class=\"token punctuation\">(</span>dna<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    d <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> dna<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> c <span class=\"token operator\">==</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">break</span>\n        d<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>dna2int<span class=\"token punctuation\">[</span>c<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> d\n\nMAX_LEN <span class=\"token operator\">=</span> <span class=\"token number\">5000</span>\nDATA_STEP <span class=\"token operator\">=</span> <span class=\"token number\">20000</span>\ndata1 <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\ndata2 <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'formalization_all_exons_lines.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f1<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'formalization_hsa_hg19_Rybak2015_lines.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f2<span class=\"token punctuation\">:</span>\n        lines_1 <span class=\"token operator\">=</span> f1<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        lines_2 <span class=\"token operator\">=</span> f2<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        data_start_number_1 <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>lines_1<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> DATA_STEP<span class=\"token punctuation\">)</span>\n        data_start_number_2 <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>lines_2<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> DATA_STEP<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data_start_number_1 :'</span><span class=\"token punctuation\">,</span> data_start_number_1<span class=\"token punctuation\">,</span> <span class=\"token string\">'data_start_number_2 :'</span><span class=\"token punctuation\">,</span> data_start_number_2<span class=\"token punctuation\">)</span>\n\n\n        dataX <span class=\"token operator\">=</span> lines_1<span class=\"token punctuation\">[</span>data_start_number_1<span class=\"token punctuation\">:</span>data_start_number_1<span class=\"token operator\">+</span>DATA_STEP<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> lines_2<span class=\"token punctuation\">[</span>data_start_number_2<span class=\"token punctuation\">:</span>data_start_number_2<span class=\"token operator\">+</span>DATA_STEP<span class=\"token punctuation\">]</span>\n        dataY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>DATA_STEP<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>DATA_STEP<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n        testX <span class=\"token operator\">=</span> lines_1<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">1000</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> lines_2<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">1000</span><span class=\"token punctuation\">]</span>\n        testY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n\ntestX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>dna_to_int<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> testX<span class=\"token punctuation\">]</span>\n\ndataX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>dna_to_int<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> dataX<span class=\"token punctuation\">]</span>\ndataY <span class=\"token operator\">=</span> dataY\n\ndata_set <span class=\"token operator\">=</span> dataX\ntest_set <span class=\"token operator\">=</span> testX\n\ntarget_set <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>dataY<span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\ntest_tag_set <span class=\"token operator\">=</span> target_set\n\ndata_set <span class=\"token operator\">=</span> sequence<span class=\"token punctuation\">.</span>pad_sequences<span class=\"token punctuation\">(</span>data_set<span class=\"token punctuation\">,</span> maxlen<span class=\"token operator\">=</span>MAX_LEN<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">'int32'</span><span class=\"token punctuation\">)</span>\ntest_set <span class=\"token operator\">=</span> sequence<span class=\"token punctuation\">.</span>pad_sequences<span class=\"token punctuation\">(</span>test_set<span class=\"token punctuation\">,</span> maxlen<span class=\"token operator\">=</span>MAX_LEN<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">'int32'</span><span class=\"token punctuation\">)</span>\ndata_set <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>data_set<span class=\"token punctuation\">)</span>\ntest_set <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>test_set<span class=\"token punctuation\">)</span>\n\ndata <span class=\"token operator\">=</span> data_set\n\nX_train <span class=\"token operator\">=</span> data_set\nY_train <span class=\"token operator\">=</span> target_set\n\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> input_dim<span class=\"token operator\">=</span>MAX_LEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> input_dim<span class=\"token operator\">=</span>MAX_LEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> Y_train<span class=\"token punctuation\">,</span> nb_epoch<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> Y_train<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    step <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\n    start_number_1 <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>lines_1<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> step<span class=\"token punctuation\">)</span>\n    start_number_2 <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>lines_2<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> step<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'start_number_1 :'</span><span class=\"token punctuation\">,</span> start_number_1<span class=\"token punctuation\">,</span> <span class=\"token string\">'start_number_2 :'</span><span class=\"token punctuation\">,</span> start_number_2<span class=\"token punctuation\">)</span>\n\n    testX <span class=\"token operator\">=</span> lines_1<span class=\"token punctuation\">[</span>start_number_1<span class=\"token punctuation\">:</span>start_number_1<span class=\"token operator\">+</span>step<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> lines_2<span class=\"token punctuation\">[</span>start_number_2<span class=\"token punctuation\">:</span>start_number_2<span class=\"token operator\">+</span>step<span class=\"token punctuation\">]</span>\n    testY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n    testX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>dna_to_int<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> testX<span class=\"token punctuation\">]</span>\n    test_set <span class=\"token operator\">=</span> sequence<span class=\"token punctuation\">.</span>pad_sequences<span class=\"token punctuation\">(</span>testX<span class=\"token punctuation\">,</span> maxlen<span class=\"token operator\">=</span>MAX_LEN<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">'int32'</span><span class=\"token punctuation\">)</span>\n    test_set <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>test_set<span class=\"token punctuation\">)</span>\n    test_tag_set <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>testY<span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>test_set<span class=\"token punctuation\">,</span> test_tag_set<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>train dataset size: 40000</li>\n<li>accuracy: 0.94082</li>\n<li>total time: 55.8 minutes</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9001d449829eccfa1f4872415a5b32d6/264eb/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 77.02702702702703%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABcRAAAXEQHKJvM/AAAA+UlEQVQ4y61UCQ7EIAjs/3/b9URB1qF3987WZCJGHGBQh1qrsjRt7TkwiMiA8cpv8R1iJnWpwvWt4yeyBcPovI6BjFBE/oIR+hD1FotlIF9k8DHDENNEeAGZEeY8EYpcRZiSaVgZGlygIVG2DPnqDLlHQKfVrkl7qulXGUJDn4q6XDVS1dDnQLBZmTdnng9YsD0em5LtAFXRXPgAXPhbh5vhLRhvyKyp+7EFnQljjD0Tnkq1KHKwNzRr3Dlo6sToAarTqSm01m84PbH9k9vG2W6rZYSllFUrSIAPAzbmRZLzHs4seyg59ebCHpxz6r3XEIJhv8aM9S97d04koOONM9qdAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/9001d449829eccfa1f4872415a5b32d6/fcda8/1.png\"\n        srcset=\"/static/9001d449829eccfa1f4872415a5b32d6/12f09/1.png 148w,\n/static/9001d449829eccfa1f4872415a5b32d6/e4a3f/1.png 295w,\n/static/9001d449829eccfa1f4872415a5b32d6/fcda8/1.png 590w,\n/static/9001d449829eccfa1f4872415a5b32d6/264eb/1.png 867w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>test dataset(random) :</p>\n<ul>\n<li>step size : 2000</li>\n<li>total size : 30</li>\n<li>accuracy : </li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/22a95e098e6955b8ec2df275ee858553/264eb/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.54054054054055%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABcRAAAXEQHKJvM/AAAB+0lEQVQ4y52S63LaMBCF/f5P1Hs6vUzbJCXNDQKEcCdAwdiWbMmyzeke2aR00v6pZzSS1rvfnj12oLWGcw5lWf73qipZzTmw1kqgwn6/f7aAP+9Vs5cV38Hf+WhbQtnCnwNjjCezGEcQPhuVS3Jx9A5wRYXp1sC48qnRfGfRX6U1kOMWRYk05yqQmAKurHzhLDQeyidKnb+XMs3ZMMZgXQN6y9Tff0wSFFIXWFEYp7kkW0yl4GGd+e7jjcFok+FqqrBVDsOfGb6PEqyTHG/aW6+I8JNOiJbEmUcLgiI36D4qX7DYCUR2etpZaJxL56tpgr6oaI1i3M4VVrHFWwEyfy4CXlxvvLrThwhxVhBo0RPgZFsrupkpP+aZhylJJEjjWuJf7iOMJe/9XegV0oKXNxuf97G38xN6YH+pxBOOFD/5wbGokmq+SXeeX91u0RW1n/o7H7t71HgtMQIZo20eOFhptKWAflxMaj/eyZkx7lRJIJv0GuDXQd3kOdDVQL7kKBfj38DOP4CfG4V/Be5Lh/uDQgG2BHgpCRy1fTRyuykmkH4dFNKGy8bD2cHD4VrX3kiQ3fg1P3RD+fra7/S2t6wnGMjHIOz8KMZ8xhbygwcuz2Fy55dKDVKTI7M5IpXKPUOUaMRyTnSKXayQKO13xpTEQsZ0hjBKYKTuFyeC0UEXzk1YAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/22a95e098e6955b8ec2df275ee858553/fcda8/2.png\"\n        srcset=\"/static/22a95e098e6955b8ec2df275ee858553/12f09/2.png 148w,\n/static/22a95e098e6955b8ec2df275ee858553/e4a3f/2.png 295w,\n/static/22a95e098e6955b8ec2df275ee858553/fcda8/2.png 590w,\n/static/22a95e098e6955b8ec2df275ee858553/264eb/2.png 867w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>","frontmatter":{"title":"Use machine learning algorithm to predict whether an RNA sequence can form a circular RNA ","date":"October 04, 2016","description":"In this problem, we are given reference genome of Homo sapiens and the genomic loci of all circRNAs. Given a certain genomic locus, our goal is to develop a classifier to predict whether a pair of two loci will form a circRNA or not","tags":["Python","machine learning","机器学习","TensorFlow"]}}},"pageContext":{"slug":"/blogs/circRNAs/","previous":{"fields":{"slug":"/blogs/hello-lucene-3/"},"frontmatter":{"title":"HelloLucene 使用Lucene搭建简易检索系统——结合Word2vec (3)"}},"next":{"fields":{"slug":"/blogs/latent-semantic-indexing/"},"frontmatter":{"title":"对zhwiki数据集进行LSI分析 (latent semantic indexing)"}}}}}