{"componentChunkName":"component---src-templates-blog-post-js","path":"/blogs/latent-semantic-indexing/","result":{"data":{"site":{"siteMetadata":{"title":"Twistronics Blog"}},"markdownRemark":{"id":"a3926556-00e5-5dae-beaa-4e448185ec1b","excerpt":"在 zhwiki 数据集中取300篇文章作为数据集，进行LSI分析，借助python的gensim库使用tfidf k取不同值时，对term-doc矩阵近似程度的变化情况\n当 k=2 时 k=3 时 k=4 时 k=10 时 可以看到，k较小时，近似效果较强，但会损失一些信息 当k取…","html":"<p>在 zhwiki 数据集中取300篇文章作为数据集，进行LSI分析，借助python的gensim库使用tfidf</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># coding:utf-8</span>\n\n<span class=\"token keyword\">from</span> gensim <span class=\"token keyword\">import</span> corpora<span class=\"token punctuation\">,</span> models\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> thulac\n<span class=\"token keyword\">import</span> heapq\n\nnews <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'news.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n    news <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nthu1 <span class=\"token operator\">=</span> thulac<span class=\"token punctuation\">.</span>thulac<span class=\"token punctuation\">(</span><span class=\"token string\">\"-seg_only\"</span><span class=\"token punctuation\">)</span>\ntexts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>thu1<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> news<span class=\"token punctuation\">]</span>\ndictionary <span class=\"token operator\">=</span> corpora<span class=\"token punctuation\">.</span>Dictionary<span class=\"token punctuation\">(</span>texts<span class=\"token punctuation\">)</span>\ncorpus <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>dictionary<span class=\"token punctuation\">.</span>doc2bow<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> text <span class=\"token keyword\">in</span> texts<span class=\"token punctuation\">]</span>\ntfidf <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>TfidfModel<span class=\"token punctuation\">(</span>corpus<span class=\"token punctuation\">)</span>\ncorpus_tfidf <span class=\"token operator\">=</span> tfidf<span class=\"token punctuation\">[</span>corpus<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">split_sen</span><span class=\"token punctuation\">(</span>document<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    doc <span class=\"token operator\">=</span> document\n    l <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'。'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'，'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">','</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'：'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'？'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'！'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'；'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> l<span class=\"token punctuation\">:</span>\n        doc <span class=\"token operator\">=</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> doc<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dedupe</span><span class=\"token punctuation\">(</span>items<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    seen <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> items<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> item <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> seen<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">yield</span> item\n            seen<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">has_num</span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    s <span class=\"token operator\">=</span> <span class=\"token string\">'1234567890'</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> s<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> i <span class=\"token keyword\">in</span> word<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n    <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n\n<span class=\"token keyword\">for</span> test_n <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">21</span><span class=\"token punctuation\">,</span><span class=\"token number\">66</span><span class=\"token punctuation\">,</span><span class=\"token number\">71</span><span class=\"token punctuation\">,</span><span class=\"token number\">87</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    test_news <span class=\"token operator\">=</span> news<span class=\"token punctuation\">[</span>test_n<span class=\"token punctuation\">]</span>\n    test_sentences <span class=\"token operator\">=</span> test_news<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'。'</span><span class=\"token punctuation\">)</span>\n    test_sentences <span class=\"token operator\">=</span> split_sen<span class=\"token punctuation\">(</span>test_news<span class=\"token punctuation\">)</span>\n\n    test_sentences <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>dedupe<span class=\"token punctuation\">(</span>test_sentences<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    sen_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> sentence <span class=\"token keyword\">in</span> test_sentences<span class=\"token punctuation\">:</span>\n        word_list <span class=\"token operator\">=</span> thu1<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">)</span>\n        tf_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        w_tf_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> tfidf<span class=\"token punctuation\">[</span>dictionary<span class=\"token punctuation\">.</span>doc2bow<span class=\"token punctuation\">(</span>word_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            tf_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>dictionary<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        temp_l <span class=\"token operator\">=</span> heapq<span class=\"token punctuation\">.</span>nlargest<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> tf_list<span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        gi <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>temp_l<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> <span class=\"token number\">4</span><span class=\"token punctuation\">:</span>\n            gi <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            gi <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n            <span class=\"token keyword\">for</span> index<span class=\"token punctuation\">,</span> g_n <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>temp_l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                gi <span class=\"token operator\">=</span> gi <span class=\"token operator\">+</span> g_n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\n        g <span class=\"token operator\">=</span> gi <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">30</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        sen_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">,</span> g<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    res <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>heapq<span class=\"token punctuation\">.</span>nlargest<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> sen_list<span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> s<span class=\"token punctuation\">:</span> s<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span> test_n <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n    res_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> res<span class=\"token punctuation\">:</span>\n        res_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> test_sentences<span class=\"token punctuation\">.</span>index<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    res <span class=\"token operator\">=</span> <span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span>res_list<span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> res<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span> s<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></code></pre></div>\n<ul>\n<li>\n<p>k取不同值时，对term-doc矩阵近似程度的变化情况\n当 k=2 时</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[[ 0.          0.16872732]\n  [ 1.          0.28385104]]\n\n [[ 0.          0.17087512]\n  [ 1.          0.25177949]]\n\n [[ 0.          0.09310504]\n  [ 1.          0.06657734]]\n\n ..., \n [[ 0.          0.12855813]\n  [ 1.          0.05259002]]\n\n [[ 0.          0.16851364]\n  [ 1.         -0.05191722]]\n\n [[ 0.          0.10435963]\n  [ 1.          0.02791414]]]</code></pre></div>\n<p>k=3 时</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[[ 0.          0.16897327]\n  [ 1.          0.28507598]\n  [ 2.          0.13649461]]\n\n [[ 0.          0.17080689]\n  [ 1.          0.24925751]\n  [ 2.          0.08284236]]\n\n [[ 0.          0.09272927]\n  [ 1.          0.06470531]\n  [ 2.          0.00207098]]\n\n ..., \n [[ 0.          0.12813977]\n  [ 1.          0.04945443]\n  [ 2.         -0.06896024]]\n\n [[ 0.          0.1677073 ]\n  [ 1.         -0.05385373]\n  [ 2.         -0.13225321]]\n\n [[ 0.          0.10473032]\n  [ 1.          0.02769582]\n  [ 2.         -0.03988227]]]</code></pre></div>\n<p>k=4 时</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[[ 0.          0.16871857]\n  [ 1.         -0.28459085]\n  [ 2.         -0.13770419]\n  [ 3.         -0.069019  ]]\n\n [[ 0.          0.17117359]\n  [ 1.         -0.25219388]\n  [ 2.         -0.08207103]\n  [ 3.         -0.09496462]]\n\n [[ 0.          0.09306016]\n  [ 1.         -0.06247403]\n  [ 2.         -0.00422359]\n  [ 3.         -0.01881501]]\n\n ..., \n [[ 0.          0.12850835]\n  [ 1.         -0.04631836]\n  [ 2.          0.06921176]\n  [ 3.         -0.1830543 ]]\n\n [[ 0.          0.16830373]\n  [ 1.          0.05348783]\n  [ 2.          0.13382081]\n  [ 3.         -0.1658659 ]]\n\n [[ 0.          0.10508035]\n  [ 1.         -0.02866824]\n  [ 2.          0.03776732]\n  [ 3.         -0.14062948]]]</code></pre></div>\n<p>k=10 时</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[[  0.00000000e+00   1.68929300e-01]\n  [  1.00000000e+00   2.81778194e-01]\n  [  2.00000000e+00   1.39412123e-01]\n  ..., \n  [  7.00000000e+00   5.72861970e-02]\n  [  8.00000000e+00  -1.24237738e-01]\n  [  9.00000000e+00  -1.26407685e-01]]\n\n [[  0.00000000e+00   1.70888003e-01]\n  [  1.00000000e+00   2.48411625e-01]\n  [  2.00000000e+00   8.09905073e-02]\n  ..., \n  [  7.00000000e+00   8.28638508e-02]\n  [  8.00000000e+00  -1.15528742e-01]\n  [  9.00000000e+00   1.88724720e-02]]\n\n [[  0.00000000e+00   9.24077340e-02]\n  [  1.00000000e+00   6.41785279e-02]\n  [  2.00000000e+00   1.33265938e-02]\n  ..., \n  [  7.00000000e+00  -7.64332711e-03]\n  [  8.00000000e+00  -2.11026728e-02]\n  [  9.00000000e+00   5.42782920e-02]]\n\n ..., \n [[  0.00000000e+00   1.28673796e-01]\n  [  1.00000000e+00   5.48490181e-02]\n  [  2.00000000e+00  -7.34370691e-02]\n  ..., \n  [  7.00000000e+00  -1.09288792e-01]\n  [  8.00000000e+00   2.09079613e-03]\n  [  9.00000000e+00   2.57721482e-01]]\n\n [[  0.00000000e+00   1.67892585e-01]\n  [  1.00000000e+00  -5.02225432e-02]\n  [  2.00000000e+00  -1.28673874e-01]\n  ..., \n  [  7.00000000e+00  -1.16714887e-02]\n  [  8.00000000e+00  -5.75828930e-03]\n  [  9.00000000e+00   2.78914422e-02]]\n\n [[  0.00000000e+00   1.04604000e-01]\n  [  1.00000000e+00   2.73290079e-02]\n  [  2.00000000e+00  -4.04171763e-02]\n  ..., \n  [  7.00000000e+00  -1.52651544e-01]\n  [  8.00000000e+00  -2.51226745e-03]\n  [  9.00000000e+00   2.34189977e-01]]]</code></pre></div>\n<p>可以看到，k较小时，近似效果较强，但会损失一些信息</p>\n</li>\n<li>当k取2时，所有相关词和相关文档投射到同一个二维潜在语义空间上的情形\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/95e86f0055ed6e88e9f76a8db421c515/9cab2/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 77.02702702702703%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABJ0AAASdAHeZh94AAABrklEQVQ4y6WT207CQBCGeRLvfGov1Bt5AQkJh0BJaDhq4o0xAVMSCAFqC9IWevzdmbK4LZUbJ9lsWabf/PPvtFSv12HbNv4bQRCg3W6jREDLsvgwSRJeFJFIiMOQd/W/okXh+/4lMI5j3l2h2F4ssF0u4btuRokEXAXatiXTkUQBZi+vMEYjOKbJL8RRhPB4RCIKyt8MUwoUtuwegM7zB/T7O7w3m1hNJqz2sN8j8DwGUhBcdsNgUYAVahpKtVoNm00KfCoDtzcmtHIDb5UKVtMpQx1RkCCR8JQhJ6WsVjyT1wTUCJgqTG/ZMBI8PAKf0xDetwN3u4U1n7Of+/UaoXiJ2iUIPfMShS5a/h0bdgVBKkRUjuDtdnw5pmHgazbD0XFSD5WWM0BqWSqMY2ohOz5q0AjJdvNjVqgwTUjBieKVqqRofCRQk5eSBWaXJ3z0xQ1fG+7MHBYB2ctTojSffMsrzbd8vmUV+FfEp5HJx4WH1WoVnU4H4/EY3W4Xg8EA/X4fuq5jJL4W2nu9XuHZcDjkd2inMxJXarVaaIqvotFonHd18ZlIpOSiPPWMWD/E42eUlZtQ/wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/95e86f0055ed6e88e9f76a8db421c515/fcda8/1.png\"\n        srcset=\"/static/95e86f0055ed6e88e9f76a8db421c515/12f09/1.png 148w,\n/static/95e86f0055ed6e88e9f76a8db421c515/e4a3f/1.png 295w,\n/static/95e86f0055ed6e88e9f76a8db421c515/fcda8/1.png 590w,\n/static/95e86f0055ed6e88e9f76a8db421c515/9cab2/1.png 864w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n其中红色圆点代表文档，蓝色叉号为单词\n相近的词会拥有较为相似的权值</li>\n<li>\n<p>分别构造原始的term-term、doc-doc矩阵，以及k取2时的term-term、doc-doc矩阵，分别画出词、文档投射到二维潜在语义空间上的情形，并对词和词、文档和文档之间的相似度进行比较\n原始的term-term矩阵为</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[ 0.00048803  0.00024793  0.00030132 ...,  0.          0.          0.        ]\n [ 0.00024793  0.00039648  0.00030132 ...,  0.          0.          0.        ]\n [ 0.00030132  0.00030132  0.0003662  ...,  0.          0.          0.        ]\n ..., \n [ 0.          0.          0.         ...,  0.01086935  0.01086935\n   0.01086935]\n [ 0.          0.          0.         ...,  0.01086935  0.01086935\n   0.01086935]\n [ 0.          0.          0.         ...,  0.01086935  0.01086935\n   0.01086935]]</code></pre></div>\n<p>原始的doc-doc矩阵为</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[ 1.          0.09597075  0.01256651 ...,  0.02078486  0.01757974\n   0.06769401]\n [ 0.09597075  1.          0.03060802 ...,  0.02004322  0.01013162\n   0.01479339]\n [ 0.01256651  0.03060802  1.         ...,  0.00817854  0.0031423\n   0.00641839]\n ..., \n [ 0.02078486  0.02004322  0.00817854 ...,  1.          0.00933102\n   0.00819435]\n [ 0.01757974  0.01013162  0.0031423  ...,  0.00933102  1.          0.01914053]\n [ 0.06769401  0.01479339  0.00641839 ...,  0.00819435  0.01914053\n   0.98913065]]</code></pre></div>\n<p>k取2时的term-term矩阵为</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[  9.35276963e+00   2.69901289e-14]\n [  2.69901289e-14   4.09090060e+00]]</code></pre></div>\n<p>doc-doc矩阵为</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[ 0.1065028   0.09890749  0.03303424 ...,  0.03655308  0.01427938\n   0.02576516]\n [ 0.09890749  0.09213056  0.03146902 ...,  0.03531263  0.01608087\n   0.02516947]\n [ 0.03303424  0.03146902  0.01250538 ...,  0.01524178  0.01248608\n   0.0115397 ]\n ..., \n [ 0.03655308  0.03531263  0.01524178 ...,  0.01929222  0.01882462\n   0.01497451]\n [ 0.01427938  0.01608087  0.01248608 ...,  0.01882462  0.03065     0.01610867]\n [ 0.02576516  0.02516947  0.0115397  ...,  0.01497451  0.01610867\n   0.01180562]]</code></pre></div>\n</li>\n<li>\n<p>当k取3时\nterm-term矩阵为</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[  9.35281176e+00  -4.56032781e-14   1.03085943e-14]\n [ -4.56032781e-14   4.09011943e+00  -6.34128167e-15]\n [  1.03085943e-14  -6.34128167e-15   3.78963029e+00]]</code></pre></div>\n<p>doc-doc矩阵为</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[[ 0.12634687  0.10942283  0.03535683 ...,  0.02701973 -0.00381796\n   0.01941215]\n [ 0.10942283  0.09709541  0.03306415 ...,  0.02955603  0.0058315\n   0.02124305]\n [ 0.03535683  0.03306415  0.01319404 ...,  0.01503685  0.01140856\n   0.01127659]\n ..., \n [ 0.02701973  0.02955603  0.01503685 ...,  0.02345334  0.02733017\n   0.01751517]\n [-0.00381796  0.0058315   0.01140856 ...,  0.02733017  0.04731181\n   0.02149145]\n [ 0.01941215  0.02124305  0.01127659 ...,  0.01751517  0.02149145\n   0.01335409]]</code></pre></div>\n<p>将相关词和相关文档投射到同一个三维潜在语义空间\n红色圆点为文档，蓝色叉号为词\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/acfdcbd73140b4b3e5d41cc7bc90a552/27b7a/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75.67567567567568%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABJ0AAASdAHeZh94AAAByElEQVQ4y3WUTU7DMBCFcyQOhcSaNQdA7DgBEiwrcYAKAYIFFRsEYsGmCIlFVZrEcRznr0k7zHM7wUmppWks2++b57HdgLit12sXwz7acrmkpml6Y9Jkra8J9oHatiVrLaVpSkVRUFmWVFWVg2NuX4LgP4cQAqS1JmOMA7pgaJ7nDo6o67pz3zn0M2AyyzIHAhABYMkJKhZnSUI5uy4lgRdw3W0ZdZLt+TCdcp+BOopIzeeUczKI7da1ON0BwlXEIgFtQpNmR5YXf9zd03QyccKMEzqXW9AOED9wF8fxAGgos+xOKfp8eqT38ZjC72/nDk4FJNDVavUHRKE7oN5sM5r/kFEzOj1r6fDghK6Pj+jr5ZWSxcLV03e3A8SgADc1NKRYGIeKbm5bujh/o4fLK3oejWg2nVIGl2xCHOJW9E4ZAz4QJ2tZYHPLCw2uNxV1wzVVZHgNgKg7AuXC+l4NcV1wKIDJIhGkKZ++Ng7ikvCcH9AorjNuSg8YhqGDIptz6IkE7rvCF7sCUNy5lyK3HIOoh2REoAQCGCbAPPpyGL237L9L9OEYcAATvosQm23dkBDOcLK+Rlow/NcYPnaBywvCF4c4hIn+F9SWhcH88os3AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/acfdcbd73140b4b3e5d41cc7bc90a552/fcda8/2.png\"\n        srcset=\"/static/acfdcbd73140b4b3e5d41cc7bc90a552/12f09/2.png 148w,\n/static/acfdcbd73140b4b3e5d41cc7bc90a552/e4a3f/2.png 295w,\n/static/acfdcbd73140b4b3e5d41cc7bc90a552/fcda8/2.png 590w,\n/static/acfdcbd73140b4b3e5d41cc7bc90a552/27b7a/2.png 804w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n</li>\n</ul>","frontmatter":{"title":"对zhwiki数据集进行LSI分析 (latent semantic indexing)","date":"October 22, 2016","description":"在 zhwiki 数据集中取300篇文章作为数据集，进行LSI分析，借助python的gensim库使用tfidf","tags":["Python","Algorithm","Natural language processing"]}}},"pageContext":{"slug":"/blogs/latent-semantic-indexing/","previous":{"fields":{"slug":"/blogs/circRNAs/"},"frontmatter":{"title":"Use machine learning algorithm to predict whether an RNA sequence can form a circular RNA "}},"next":{"fields":{"slug":"/blogs/cs231n-Practical-Machine-Learning-Project-2/"},"frontmatter":{"title":"cs231n: Practical Machine Learning Project 2"}}}}}