{"componentChunkName":"component---src-templates-blog-post-js","path":"/blogs/synonymous-sentences-detection/","result":{"data":{"site":{"siteMetadata":{"title":"Twistronics Blog"}},"markdownRemark":{"id":"f6a94c8f-cb7d-5629-9d6b-462cad8cd3d2","excerpt":"同义句检测： 对于表述方式不同的两句话判断是否含义类似 example： true （是同义句） 应用： 问答系统中对于问题和答案的识别和处理 文本压缩和摘要提取过程中识别排除含义相同的句子 信息和数据库的生成和收集 提高用户交互过程中的理解能力 作为一个重要的传统任务，以往的方法可以大概分为…","html":"<p>同义句检测： 对于表述方式不同的两句话判断是否含义类似</p>\n<p>example：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">The Prime Minister, Junichiro Koizumi, joined the criticism.\nPrime Minister Junichiro Koizumi said Mr Ota deserved to be criticised.</code></pre></div>\n<p>true （是同义句）</p>\n<p>应用：</p>\n<ul>\n<li>问答系统中对于问题和答案的识别和处理</li>\n<li>文本压缩和摘要提取过程中识别排除含义相同的句子</li>\n<li>信息和数据库的生成和收集</li>\n<li>提高用户交互过程中的理解能力</li>\n</ul>\n<p>作为一个重要的传统任务，以往的方法可以大概分为3类：</p>\n<ol>\n<li>\n<h4>基于规则的配对</h4>\n<p>早期会有基于规则的判断方法，通过替换词语、构建模板等方法结合语料库进行学习，这样的最大缺点是费时费力，且灵活度不高\nexample：</p>\n<ol>\n<li>∀x ∀y assassinate(x, y)\n⇒ kill(x, y) </li>\n<li>why do we use X?\nwhat  did X replace ?</li>\n</ol>\n</li>\n<li>\n<h4>基于相似度</h4>\n<p>另外一个常见的方法是在word embedding之后提取句子的一些特征来看两个句子的相似度是否大于一定的阈值，常用的特征有：实体重叠程度、consine。</p>\n<p>单词嵌入+字符串特征</p>\n<ol>\n<li>cosine similarity</li>\n<li>named entity overlapping</li>\n<li>unmatched word </li>\n<li>sentence focus feature</li>\n<li>Tree-editing distance</li>\n</ol>\n</li>\n<li>\n<h4>基于神经网络的学习</h4>\n<p>最后一种，是通过神经网络如CNN RNN 等训练，进行判断。这种方法不仅人工参与少，而且比较灵活，实验结果也很可观。</p>\n<ol>\n<li>学习到句子特征向量</li>\n<li>用分类器判断</li>\n<li>神经网络模型多种：</li>\n<li>RNN /CNN /LSTM</li>\n</ol>\n</li>\n</ol>\n<p>通过观察数据，我们可以得到两个特点</p>\n<ol>\n<li>\n<p>同义句很多基于同义的短语</p>\n<p>example： is the author of  &#x3C;=>  wrote ;<br>\nis the key to       &#x3C;=>  is very important</p>\n</li>\n<li>\n<p>同义句之间有很多短语部分的顺序调整</p>\n<p>example：according to A 可以在句首、句中、句尾</p>\n</li>\n</ol>\n<p>处理句子对的结构\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6c3718651caed2aae96081c05f74cd53/1ddef/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 85.8108108108108%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAA85AAAPOQE6gPqvAAACgElEQVQ4y4VUa3PaMBDk//+udJJMPuQBBDrQpA2UBPyQbNmyLdts9w5ITNJpNXNIOq3Wt3cnRvv9HmIy5Pe0H/rzPEdZlgfMp/Oz+5xHGI7jweeRpilWqxX+NU6kI1s1SH2DrA5qSeERu/LdDM92eYF1lOh5lH+cCdbSZ493d0WFkSFh6Hr9Qk9zRYkmBF3nzmE+/w5jLKI4xmw+h80yPQvEFKVHaDvdy3h1JBTmtu/fQ6+bQMIOxmZISbSLYpLkJC/w+rYlcQKbOyUS7DCHW4lQwu0GSZUCFEUBay2apvmSq6qqkDFKwcm8H+T9QEjJZVWjpQQB/3p5wXK5RFXX6Pv+SxXFV/Ps+fkZj4+P+tGGkbahwZtITssKjrnYE9h13fvXPMlDaHUtJP0xLZK7um7Oqiv3JJhN7g+EnoCezru7O0wmUwU1x/xIgbz3ekGIOhKHttWunU6nuL29Rcu9KNywA0bG11g8PeGeZFfX17i8vMLD/T0WiyXiJFHi2WzG/UIJoyjCE/Hjhwfc3Nzg4uKbBvKDaVLJCSOUHG7WayWcjCfYbneMqNY8ijkWSfaeVnqvEb69bnBN/Hg8xnr9G4G51AhPkmV0g/YRqZIbLQKjFJPzlr62/cjtqWAfkllly64X0tRklGl0ndE3LNJpiM/xhQgmilP2a64KSxZWJUvbOD58Kb/jy5D+krUATpXVN36MRHxSJMFIH0rPShvVLNoxhzWSzKFgcRJGGKVW12lWUHarz6rrDybrhnJFkSNmRzUpI8yZtowv6bdItlXQDk85rxKLl9joOuaH/mr+MAvm5y7BxuRIBM8/kYj+s7+vsiyQ8cn9fxzkW2P4RM2Z7w+2hiL4vF3dHAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/6c3718651caed2aae96081c05f74cd53/fcda8/1.png\"\n        srcset=\"/static/6c3718651caed2aae96081c05f74cd53/12f09/1.png 148w,\n/static/6c3718651caed2aae96081c05f74cd53/e4a3f/1.png 295w,\n/static/6c3718651caed2aae96081c05f74cd53/fcda8/1.png 590w,\n/static/6c3718651caed2aae96081c05f74cd53/1ddef/1.png 635w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>第一步对句子进行建模\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4597ef4e8cea0ca7b172f41da0118bf2/41d3b/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.27027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABJ0AAASdAHeZh94AAABqklEQVQoz21S2ZKkMAzj//9va4YbGsjFFSA0Rx8akZ6nqU2VMXEsR3Ic4He9af/CFGGSoxLa261RKGqJKLvRK8R5hbRsUDJWVMKflYxbt+P1/tQJHseBdZ6xuRVaavRtDzvOELJF0xhvSg9Q0jDWoREtpPcdht7CDhPGfiTewU0Tgm1ZUPLWKM7pa2T5DeWtQRhlEKrHPC043cLkGSkZFmXF3AxxUuCbOWlWIi8YJ0Y0mgy3Db3WELcaOQ/DKEdBiboR6EwLqyR0GKLNMmghIasGhr7kxXFSImNhVQtIWisVAi0UWsoc7QLFvnWK/eNNxnTouwFGGayUciUb3VLmCE1fVQrzMNBLCGFg7QxNUkH0nSBJC7T9RFYK0VeMkg2PyTKjlAuwujtqSkrS0su+pNbMEZR/YS/ZFXucf0UI9nX1Df08jMPB/chmG92T4ejZPR8nHseOxZKp6alowDxOOPfdYz41VjhrEeDP2s4XRnf4f7edWLaHH6lrLK748Xz7/f144H8reL+ZQOMHz9cLqptghtkX68YFsrXYCHb3HdKM6Kf1d3A/uL/2Aynypuy7TL89AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/4597ef4e8cea0ca7b172f41da0118bf2/fcda8/2.png\"\n        srcset=\"/static/4597ef4e8cea0ca7b172f41da0118bf2/12f09/2.png 148w,\n/static/4597ef4e8cea0ca7b172f41da0118bf2/e4a3f/2.png 295w,\n/static/4597ef4e8cea0ca7b172f41da0118bf2/fcda8/2.png 590w,\n/static/4597ef4e8cea0ca7b172f41da0118bf2/41d3b/2.png 774w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>LSTM网络在处理句子信息方面效果比较突出，它可以通过三个门结构适当保留之前的句子信息</p>\n<ul>\n<li>\n<p>基于树结构的LSTM网络建模</p>\n<ol>\n<li>自底向上合成  </li>\n<li>词向量经过预训练处理</li>\n</ol>\n</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/faadaf141662b5a302a3d1849820c492/8c381/3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.5945945945946%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABcRAAAXEQHKJvM/AAABJUlEQVQoz4WSi26DMAxF+f+fBNExKsojEN4E3BxDJjpNWqQQjPHhXuNonmcxxsjj8SVd10nbtvJ6lTKOoz43ppVjP4S1rqssyyLObf5+k23bNB6GUcZp0jha/EtAqqqWvu99ctBCkmwKj+MEkivLUs+qqrTu+XxKHMeSZd9S17VE6wXM89wDB6/SqlKUW9urUoAB+t9SIMqaxmgx98CCHc4AC+D7B5xzH+8okF4VRaGKrLUKBsYZFN6BcgPiBndAFUjiVNgo5N7Hfd9/rPxWF/bie7zf4gh79K1tz77RTxRP/q8BD3b+6iE/3/nLOQQXECUUB5tYJuY5SonpEws4TvgQVtfL5kcPKWbWwuwxPqEI1UBDfwAzLuTZrDRN/chkkiSJCnkDX4O9gcbgTScAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"3\"\n        title=\"3\"\n        src=\"/static/faadaf141662b5a302a3d1849820c492/fcda8/3.png\"\n        srcset=\"/static/faadaf141662b5a302a3d1849820c492/12f09/3.png 148w,\n/static/faadaf141662b5a302a3d1849820c492/e4a3f/3.png 295w,\n/static/faadaf141662b5a302a3d1849820c492/fcda8/3.png 590w,\n/static/faadaf141662b5a302a3d1849820c492/efc66/3.png 885w,\n/static/faadaf141662b5a302a3d1849820c492/c83ae/3.png 1180w,\n/static/faadaf141662b5a302a3d1849820c492/8c381/3.png 1267w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>我们知道，LSTM在产生最终的句子向量的过程中，会产生一系列的隐状态，这些隐状态节点向量实际就是我们需要的短语向量。\n然后我们构建一个相似矩阵，包含了两个句子中的所有短语向量之间的比较。矩阵的元素是节点i和节点j的距离（差异程度）\n为保证信息利用的更加充分，我们用相同的方法构建单词之间的相似矩阵</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7ad7063b2c4be9a5c0ec981c9ee0e5b3/20982/4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.4054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAABuUlEQVQoz31T246cMAzl/z+pD31opapSK1XVbtWV2KKZ4TpkgJALCSSZU8M2lFWrtWTFkOT42MdJ7vc7/mfxf1yt1hBtC8EY5O22xZJi3XVA8PEWknVZXIDQM7iy27o4v4NFQHY6oXp8AC8LiKbBWJao0194+vwFjPVQ1iGEgGSZZ4xComw5Ls2AbtSv2UWGUsKQ22mCUQpq5GivDMWVo2hHjMps55L0OcO79x/Rj+qFyaAxSItlcdv3mjXPc6RpioaYRfv2/REfPn2FsQs8nbn2lGRakJzzEk9phvkPAJeGmHIYYwh0gabeZVm2Azo6Z8yEh5/P+JGe92rWe0JbJEdRAsUj9XGirGsJkkqcJvNKLCkEFCXpOO3Nbu93tCSW9SKOR8kEleFQ3STm2f6jfvAOg9BgfIIkRk0ndzIrueSo5Eo5pwbXnUJFwD0X8ARQ1zVOpLIlAdc2XAmkZBJNr1FS4nAQMTnOWgj3rcHeezjnYK0lljOqqkJRFGDkA82epf6uam/75LHCHfAI+pYNBNyfT9swr7M4kPqrc4qD9397eJy7t1wNNKdU+sSH7ZWIpkZ/uWwvJ2L8BpXMUv53jg7bAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"4\"\n        title=\"4\"\n        src=\"/static/7ad7063b2c4be9a5c0ec981c9ee0e5b3/fcda8/4.png\"\n        srcset=\"/static/7ad7063b2c4be9a5c0ec981c9ee0e5b3/12f09/4.png 148w,\n/static/7ad7063b2c4be9a5c0ec981c9ee0e5b3/e4a3f/4.png 295w,\n/static/7ad7063b2c4be9a5c0ec981c9ee0e5b3/fcda8/4.png 590w,\n/static/7ad7063b2c4be9a5c0ec981c9ee0e5b3/20982/4.png 778w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>接下来我们将把两个矩阵输入到分类器中判断，因为句子是不等长的，所以我们需要加一步dynamic pooling的处理,可以输出等维度的矩阵\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ca8f32b486936e49958eef890bbc01e2/108f8/6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.70270270270271%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAABu0lEQVQoz3VTyW7bMBDV/39QTz3mUCABAqM2ajRoHVhypGglKW6iKL/OUHFgp8kAhAyJ87YZZ7iq8/l88+RyUqLPjzg+3EOcTpi9/+/OdWX84eNJDcuSwMzQQ9Y1mucDxraF7jr4ccRnfXwyav2UKYYAUVUYOwLpe1gGFwKqaTA5h68qWwhvtBOk8ZDaw/qZ9cEOA5zgI0iRSpdZmSECfmdIaZgXhLikpw8RCysUQqJsBJ7LAVU3wk3hne2S16WWGDEZQ3FEOGtR9wp/ig6Hlx6Dsqvlux8POORlapDaQbsZE7FxhnGaYLmRMqzIvubsCDTMEb/2e+yf/qbfxk3J3Uxqs/vHn+jEasn6gN/HltgMAoHFeUae59hsNthut+jIJqtWBPzt+x0et0+rcsqtbBVee307FAbUlKeiPA0pkzSImUAjqWI7gQbVNTU02W7IrpvizWa8rc3KwPXSKAp3piw1RmMT2MeyNKBGGCImcGmJfHrfy5ThBZ0nVbYjKpL92psUeHxTp5RKqjgGrSSKWiZ7p2a1+QVgJFV+HQzZ7gYJT3lxbrvdDkVRwNP+jZQf31M0BI6GV+76H/YPd9FU1WxH4qAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"6\"\n        title=\"6\"\n        src=\"/static/ca8f32b486936e49958eef890bbc01e2/fcda8/6.png\"\n        srcset=\"/static/ca8f32b486936e49958eef890bbc01e2/12f09/6.png 148w,\n/static/ca8f32b486936e49958eef890bbc01e2/e4a3f/6.png 295w,\n/static/ca8f32b486936e49958eef890bbc01e2/fcda8/6.png 590w,\n/static/ca8f32b486936e49958eef890bbc01e2/108f8/6.png 777w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>","frontmatter":{"title":"Synonymous Sentences Detection","date":"June 02, 2017","description":"使用基于短语的机器学习模型，对于表述方式不同的两句话判断是否含义类似","tags":["Algorithm","Natural language processing","Machine learning","机器学习"]}}},"pageContext":{"slug":"/blogs/synonymous-sentences-detection/","previous":{"fields":{"slug":"/blogs/Combinatory-categorial-grammar/"},"frontmatter":{"title":"Combinatory categorial grammar"}},"next":null}}}